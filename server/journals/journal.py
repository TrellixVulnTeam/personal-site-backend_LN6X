journalDict = {
    "weektwo": {
        "title": "Bias in the Digital Humanities",
        "subtitle": "Week 2 Reflection",
        "text": [
            "As researchers, historians, and students involved in digital humanities projects, we must stop and think about how bias creeps in to the projects that we’re designing and using, and how we can make conscious choices to weed out its existence.  Furthermore, we must make efforts to reflect on a larger scale. As stated by Jessica Lu in Confronting the Witness, “How will we be able to share with and learn from others if our personal work-arounds remain just that: personal?”.",
            "Digital humanities projects are such powerful tools, as they are able to use existing software and technologies, as well as adapting to make their own, in order to visualize, present, and analyze history archives. For example, in the Dartmouth Digital History Initiative (DDHI), we use the Oral Histories (OH) Encoder to make a preliminary pass at adding XML tags to oral history transcripts, which research assistants later check over. The OH Encoder is a machine learning software which was trained using previously encoded transcripts, and has proved to be a huge time saver in the project.",
            "When we see the work of cognitive systems like the OH Encoder, it seems almost human. Maybe this is a bit of a stretch - as a long time research assistant at the DDHI, I could easily see the mistakes that the encoder was making repeatedly. However, when working with a less experienced partner on a transcript, they agreed with many of the small mistakes that the encoder made. In Chapter 3 of Bodies of Information, the author talks about how we have “underexplored … the way that the “human” is articulated, produced, and normed in the drive toward emulating “human” processes”. It is later explained in this chapter that the level of cognition that a machine has may seem human to some, but quite a bit off to others. Back to my example of the DDHI: as an experienced encoder, I find myself sometimes frustrated with the level of understanding the OH Encoder has of our schema. It frequently tags places incorrectly, misses important events which blend into the transcript by nature of human speech, and forces me to spend extra time parsing through dates to add the “when” attribute to all of the tags, on top of removing imprecise date mentions such as “summer”, “that year”, or “fall term”. However, to an inexperienced research assistant, the cognition and performance of the machine seems incredible. To someone who is just beginning to learn the DDHI encoding schema, the level of cognition seems like an unbelievable development - likely because it matches their own knowledge of it.",
            "When using the OH Encoder, we have to carefully comb through interviews to add and fix tags which are slightly off. These missed/incorrect tags seem to oftentimes contain names of places in Vietnam, and foreign or uncommon names, among other things. Since the people who are being interviewed are often English speaking, white men, educated in New England, these names and place references can be less common in interviews, therefore less available in data training sets. These are the same names that are sometimes missed even by more experienced research assistants. Using a Euro/North American centric data set to train our system created bias in unintended aspects of the project. This is the same issue which Bodies of Information warns can happen with the “Large-Scale Image Memorability” example in Chapter 3. Training a system with biased data will lead to the expected: a biased system.",
            "Bias in Computer Systems, by Batya Friedman, and Helen Nissenbaum explains the ways that developers can view, identify, and limit biases present in systems they design. Besides the pre-existing bias, which in the DDHI example would emerge from the pool of interviewees, one that seems extremely important to consider in the context of a digital humanities project is the mismatch between users and system design (3.2 in the chapter). Making a timeline of an interview is something that needs to be designed as not in a strictly “how to humans read and perform research from an interview” manner, but in a “how do we, as humans, imagine, think temporally, and piece together and imagine the information that is presented to us” manner. It’s one thing to recognize the dates of the Vietnam War and present the events from an interview which occur between that start and end, but contextually more important to think about the movements of the story teller, life changing events which may be harder to grab and place from the interview, like when they had children, and how their attitudes and sentiment about the war was changing over that timeframe.",
            "Being involved in digital humanities projects, and making use of the resources they provide us with presents us with unprecedented opportunity, but also requires caution and care. By creating these resources, we must consider the context of their use and the dissemination of bias throughout our projects."
        ],
        "sources": [
            "Friedman, Batya, and Helen Nissenbaum. \"Bias in Computer Systems.\" ACM Transactions on Information Systems 14.3 (1996): 330-47. Print.",
            "Risam, Roopika. \"What Passes for Human?: Undermining the Universal Subject in Digital Humanities Praxis.\" Bodies of Information: Intersectional Feminism and the Digital Humanities, edited by Elizabeth Losh and Jacqueline Wernimont, University of Minnesota Press, Minneapolis; London, 2018, pp. 39–56. JSTOR, www.jstor.org/stable/10.5749/j.ctv9hj9r9.6. Accessed 29 June 2021.",
            "Lu, Jessica. \"Confronting \"the Witness\": Encoding Archives of Black Lives.\" African American History, Culture & Digital Humanities. 04 Aug. 2017. Web. 29 June 2021." 
        ]
    },
    "weekthree": {
        "title": "Digital Humanities and Oral Histories, Bias and Interpretation",
        "subtitle": "Week 3 Reflection",
        "text": [
            "hi."
        ],
        "sources": [
            "Boyd, Danah. (2011). \"White Flight in Networked Publics? How Race and Class Shaped American Teen Engagement with MySpace and Facebook.\" In Race After the Internet (eds. Lisa Nakamura and Peter A. Chow-White). Routledge, pp. 203-222.",
            "Dougherty, Jack, and Kristen Nawrotzki. \"Writing History in the Digital Age.\" Digital Humanities (2013). Print.",
            "Yow, Valerie Raleigh. \"Recording Oral History a Guide for the Humanities and Social Sciences\". Rowman & Littlefield, 2015. Print." 
        ]
    }
}